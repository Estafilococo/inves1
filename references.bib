@inproceedings{keshet2016prediction,
  title        = {Prediction-Based, Prioritized Market-Share Insight Extraction},
  author       = {Keshet, Renato and Maor, Alina and Kour, George},
  booktitle    = {Advanced Data Mining and Applications: 12th International Conference, ADMA 2016, Gold Coast, QLD, Australia, December 12-15, 2016, Proceedings 12},
  pages        = {81--94},
  year         = {2016},
  organization = {Springer}
}
@article{cheng2000BiclusteringExpressionData,
  title        = {Biclustering of {{Expression Data}}},
  author       = {Cheng, Yizong and Church, G.},
  date         = {2000},
  journaltitle = {Proceedings. International Conference on Intelligent Systems for Molecular Biology},
  shortjournal = {Proceedings. International Conference on Intelligent Systems for Molecular Biology},
  url          = {https://www.cs.princeton.edu/courses/archive/fall03/cs597F/Articles/biclustering_of_expression_data.pdf},
  urldate      = {2023-04-18},
  abstract     = {An efficient node-deletion algorithm is introduced to find submatrices in expression data that have low mean squared residue scores and it is shown to perform well in finding co-regulation patterns in yeast and human. An efficient node-deletion algorithm is introduced to find submatrices in expression data that have low mean squared residue scores and it is shown to perform well in finding co-regulation patterns in yeast and human. This introduces \&quot;biclustering\&quot;, or simultaneous clustering of both genes and conditions, to knowledge discovery from expression data. This approach overcomes some problems associated with traditional clustering methods, by allowing automatic discovery of similarity based on a subset of attributes, simultaneous clustering of genes and conditions, and overlapped grouping that provides a better representation for genes with multiple functions or regulated by many factors.},
  langid       = {english}
}
@article{madeira2004BiclusteringAlgorithmsBiological,
  title        = {Biclustering Algorithms for Biological Data Analysis: {{A}} Survey},
  author       = {Madeira, Sara C. and Oliveira, Arlindo L.},
  date         = {2004},
  journaltitle = {IEEE/ACM Transactions on Computational Biology and Bioinformatics},
  shortjournal = {IEEE/acm Trans. Comput. Biol. Bioinformatics},
  eprint       = {17048406},
  eprinttype   = {pmid},
  doi          = {10.1109/tcbb.2004.2},
  abstract     = {A large number of clustering approaches have been proposed for the analysis of gene expression data obtained from microarray experiments. However, the results from the application of standard clustering methods to genes are limited. This limitation is imposed by the existence of a number of experimental conditions where the activity of genes is uncorrelated. A similar limitation exists when clustering of conditions is performed. For this reason, a number of algorithms that perform simultaneous clustering on the row and column dimensions of the data matrix has been proposed. The goal is to find submatrices, that is, subgroups of genes and subgroups of conditions, where the genes exhibit highly correlated activities for every condition. In this paper, we refer to this class of algorithms as biclustering. Biclustering is also referred in the literature as coclustering and direct clustering, among others names, and has also been used in fields such as information retrieval and data mining. In this comprehensive survey, we analyze a large number of existing approaches to biclustering, and classify them in accordance with the type of biclusters they can find, the patterns of biclusters that are discovered, the methods used to perform the search, the approaches used to evaluate the solution, and the target applications.},
  mag_id       = {2144544802},
  pmcid        = {null}
}
@article{kim2022ABCAttributedBipartite,
  title        = {{{ABC}}: {{Attributed}} Bipartite Co-Clustering},
  shorttitle   = {{{ABC}}},
  author       = {Kim, Junghoon and Feng, Kaiyu and Cong, Gao and Zhu, Diwen and Yu, Wenyuan and Miao, Chunyan},
  date         = {2022-06-01},
  journaltitle = {Proceedings of the VLDB Endowment},
  shortjournal = {Proceedings of the VLDB Endowment},
  volume       = {15},
  number       = {10},
  pages        = {2134--2147},
  issn         = {2150-8097},
  doi          = {10.14778/3547305.3547318},
  abstract     = {Finding a set of co-clusters in a bipartite network is a fundamental and important problem. In this paper, we present the Attributed Bipartite Co-clustering (ABC) problem which unifies two main concepts: (i) bipartite modularity optimization, and (ii) attribute cohesiveness. To the best of our knowledge, this is the first work to find co-clusters while considering the attribute cohesiveness. We prove that ABC is NP-hard and is not in APX, unless P=NP. We propose three algorithms: (1) a top-down algorithm; (2) a bottom-up algorithm; (3) a group matching algorithm. Extensive experimental results on real-world attributed bipartite networks demonstrate the efficiency and effectiveness of our algorithms.}
}
@inproceedings{dongkuanxu2019DeepCoClustering,
  title        = {Deep co-clustering},
  author       = {Xu, Dongkuan and Cheng, Wei and Zong, Bo and Ni, Jingchao and Song, Dongjin and Yu, Wenchao and Chen, Yuncong and Chen, Haifeng and Zhang, Xiang},
  booktitle    = {Proceedings of the 2019 SIAM International Conference on Data Mining},
  pages        = {414--422},
  year         = {2019},
  organization = {SIAM}
}@article{lin2019OverviewCoClusteringMatrix,
  title        = {An Overview of Co-Clustering via Matrix Factorization},
  author       = {Lin, Renjie and Wang, Shiping and Guo, Wenzhong},
  date         = {2019},
  journaltitle = {IEEE Access},
  shortjournal = {IEEE Access},
  volume       = {7},
  pages        = {33481--33493},
  issn         = {2169-3536},
  doi          = {10.1109/ACCESS.2019.2904314},
  abstract     = {Co-clustering algorithms have been widely used for text clustering and gene expression through matrix factorization. In recent years, diverse co-clustering algorithms which group data points and features synchronously have shown their advantages over traditional one-side clustering. In order to solve the co-clustering problems, most existing methods relaxed constraints via matrix factorization. In this paper, we provide a detailed understanding of six co-clustering algorithms with different performance and robustness. We conduct comprehensive experiments in eight real-world datasets to compare and evaluate these co-clustering methods based on four evaluation metrics including clustering accuracy, normalized mutual information, adjusted rand index, and purity. Our findings demonstrate the strengths and weaknesses of these methods and provide insights to motivate further exploration of co-clustering methods and matrix factorization.},
  eventtitle   = {{{IEEE Access}}}
}
@inproceedings{siklosi2012ContentbasedTrustBias,
  title      = {Content-Based Trust and Bias Classification via Biclustering},
  booktitle  = {Proceedings of the 2nd {{Joint WICOW}}/{{AIRWeb Workshop}} on {{Web Quality}}},
  author     = {Sikl\'osi, D\'avid and Dar\'oczy, B\'alint and Bencz\'ur, Andr\'as A.},
  date       = {2012-04-16},
  series     = {{{WebQuality}} '12},
  pages      = {41--47},
  publisher  = {{Association for Computing Machinery}},
  location   = {{New York, NY, USA}},
  doi        = {10.1145/2184305.2184314},
  abstract   = {In this paper we improve trust, bias and factuality classification over Web data on the domain level. Unlike the majority of literature in this area that aims at extracting opinion and handling short text on the micro level, we aim to aid a researcher or an archivist in obtaining a large collection that, on the high level, originates from unbiased and trustworthy sources. Our method generates features as Jensen-Shannon distances from centers in a host-term biclustering. On top of the distance features, we apply kernel methods and also combine with baseline text classifiers. We test our method on the ECML/PKDD Discovery Challenge data set DC2010. Our method improves over the best achieved text classification NDCG results by over 3--10\% for neutrality, bias and trustworthiness. The fact that the ECML/PKDD Discovery Challenge 2010 participants reached an AUC only slightly above 0.5 indicates the hardness of the task.在本文中，我们在域级别上改进了对 Web 数据的信任、偏见和事实分类。与该领域的大多数旨在从微观层面提取意见\hspace{0pt}\hspace{0pt}和处理短文本的文献不同，我们的目标是帮助研究人员或档案管理员获得大量收藏，这些收藏在高层次上来自公正和可信赖的来源。我们的方法生成的特征是 Jensen-Shannon 与主项双聚类中心的距离。在距离特征之上，我们应用内核方法并结合基线文本分类器。我们在 ECML/PKDD 发现挑战数据集 DC2010 上测试了我们的方法。我们的方法在中立性、偏见和可信度方面比最佳实现的文本分类 NDCG 结果提高了 3--10\% 以上。事实上，2010 年 ECML/PKDD 发现挑战赛参与者达到的 AUC 仅略高于 0.5，这表明任务的难度。},
  eventtitle = {Joint {{WICOW}}/{{AIRWeb Workshop}} on {{Web Quality}}},
  isbn       = {978-1-4503-1237-0},
  langid     = {english}
}

@article{song2013ConstrainedTextCoclustering,
  author   = {Song, Yangqiu and Pan, Shimei and Liu, Shixia and Wei, Furu and Zhou, Michelle X. and Qian, Weihong},
  journal  = {IEEE Transactions on Knowledge and Data Engineering},
  title    = {Constrained Text Coclustering with Supervised and Unsupervised Constraints},
  year     = {2013},
  volume   = {25},
  number   = {6},
  pages    = {1227-1239},
  abstract = {In this paper, we propose a novel constrained coclustering method to achieve two goals. First, we combine information-theoretic coclustering and constrained clustering to improve clustering performance. Second, we adopt both supervised and unsupervised constraints to demonstrate the effectiveness of our algorithm. The unsupervised constraints are automatically derived from existing knowledge sources, thus saving the effort and cost of using manually labeled constraints. To achieve our first goal, we develop a two-sided hidden Markov random field (HMRF) model to represent both document and word constraints. We then use an alternating expectation maximization (EM) algorithm to optimize the model. We also propose two novel methods to automatically construct and incorporate document and word constraints to support unsupervised constrained clustering: 1) automatically construct document constraints based on overlapping named entities (NE) extracted by an NE extractor; 2) automatically construct word constraints based on their semantic distance inferred from WordNet. The results of our evaluation over two benchmark data sets demonstrate the superiority of our approaches against a number of existing approaches.},
  keywords = {},
  doi      = {10.1109/TKDE.2012.45},
  issn     = {1558-2191},
  month    = {6},
}

@article{khan2020CoClusteringRevealSalient,
  title        = {Co-{{Clustering}} to {{Reveal Salient Facial Features}} for {{Expression Recognition}}},
  author       = {Khan, Sheheryar and Chen, Lijiang and Yan, Hong},
  date         = {2020-04-01},
  journaltitle = {IEEE Transactions on Affective Computing},
  shortjournal = {IEEE Trans. Affective Comput.},
  volume       = {11},
  number       = {2},
  pages        = {348--360},
  issn         = {1949-3045, 2371-9850},
  doi          = {10.1109/TAFFC.2017.2780838},
  abstract     = {Facial expressions are a strong visual intimation of gestural behaviors. The intelligent ability to learn these non-verbal cues of the humans is the key characteristic to develop efficient human computer interaction systems. Extracting an effective representation from facial expression images is a crucial step that impacts the recognition accuracy. In this paper, we propose a novel feature selection strategy using singular value decomposition (SVD) based co-clustering to search for the most salient regions in terms of facial features that possess a high discriminating ability among all expressions. To the best of our knowledge, this is the first known attempt to explicitly perform co-clustering in the facial expression recognition domain. In our method, Gabor filters are used to extract local features from an image and then discriminant features are selected based on the class membership in co-clusters. Experiments demonstrate that co-clustering localizes the salient regions of the face image. Not only does the procedure reduce the dimensionality but also improves the recognition accuracy. Experiments on CK plus, JAFFE and MMI databases validate the existence and effectiveness of these learned facial features.},
  eventtitle   = {{{IEEE Transactions}} on {{Affective Computing}}},
  langid       = {english}
}
@inproceedings{daruru2009PervasiveParallelismData,
  title      = {Pervasive Parallelism in Data Mining: Dataflow Solution to Co-Clustering Large and Sparse {{Netflix}} Data},
  shorttitle = {Pervasive Parallelism in Data Mining},
  booktitle  = {Proceedings of the 15th {{ACM SIGKDD}} International Conference on {{Knowledge}} Discovery and Data Mining},
  author     = {Daruru, Srivatsava and Marin, Nena M. and Walker, Matt and Ghosh, Joydeep},
  date       = {2009-06-28},
  series     = {{{KDD}} '09},
  pages      = {1115--1124},
  publisher  = {{Association for Computing Machinery}},
  location   = {{New York, NY, USA}},
  doi        = {10.1145/1557019.1557140},
  abstract   = {All Netflix Prize algorithms proposed so far are prohibitively costly for large-scale production systems. In this paper, we describe an efficient dataflow implementation of a collaborative filtering (CF) solution to the Netflix Prize problem [1] based on weighted coclustering [5]. The dataflow library we use facilitates the development of sophisticated parallel programs designed to fully utilize commodity multicore hardware, while hiding traditional difficulties such as queuing, threading, memory management, and deadlocks.迄今为止提出的所有 Netflix Prize 算法对于大规模生产系统来说成本都高得令人望而却步。在本文中，我们描述了基于加权共聚 [5] 的 Netflix Prize 问题 [1] 协同过滤 (CF) 解决方案的高效数据流实现。我们使用的数据流库有助于开发旨在充分利用商用多核硬件的复杂并行程序，同时隐藏排队、线程、内存管理和死锁等传统困难。 The dataflow CF implementation first compresses the large, sparse training dataset into co-clusters. Then it generates recommendations by combining the average ratings of the co-clusters with the biases of the users and movies. When configured to identify 20x20 co-clusters in the Netflix training dataset, the implementation predicted over 100 million ratings in 16.31 minutes and achieved an RMSE of 0.88846 without any fine-tuning or domain knowledge. This is an effective real-time prediction runtime of 9.7 us per rating which is far superior to previously reported results. Moreover, the implemented co-clustering framework supports a wide variety of other large-scale data mining applications and forms the basis for predictive modeling on large, dyadic datasets [4, 7].数据流 CF 实现首先将大型稀疏训练数据集压缩为联合集群。然后，它通过将共同集群的平均评分与用户和电影的偏见相结合来生成推荐。当配置为识别 Netflix 训练数据集中的 20x20 联合集群时，该实施在 16.31 分钟内预测了超过 1 亿个评级，并且在没有任何微调或领域知识的情况下实现了 0.88846 的 RMSE。这是每次评级 9.7 us 的有效实时预测运行时间，远优于之前报告的结果。此外，已实施的联合聚类框架支持各种其他大规模数据挖掘应用程序，并构成了对大型二元数据集进行预测建模的基础 [4、7]。},
  eventtitle = {{{ACM Knowledge Discovery}} and {{Data Mining}}},
  isbn       = {978-1-60558-495-9},
  langid     = {english}
}
@article{kluger2003SpectralBiclusteringMicroarray,
  title = {Spectral {{Biclustering}} of {{Microarray Data}}: {{Coclustering Genes}} and {{Conditions}}},
  shorttitle = {Spectral {{Biclustering}} of {{Microarray Data}}},
  author = {Kluger, Yuval and Basri, Ronen and Chang, Joseph T. and Gerstein, Mark},
  date = {2003-04-01},
  journaltitle = {Genome Research},
  shortjournal = {Genome Res.},
  volume = {13},
  number = {4},
  eprint = {12671006},
  eprinttype = {pmid},
  pages = {703--716},
  publisher = {{Cold Spring Harbor Lab}},
  issn = {1088-9051, 1549-5469},
  doi = {10.1101/gr.648603},
  abstract = {Global analyses of RNA expression levels are useful for classifying genes and overall phenotypes. Often these classification problems are linked, and one wants to find ``marker genes'' that are differentially expressed in particular sets of ``conditions.'' We have developed a method that simultaneously clusters genes and conditions, finding distinctive ``checkerboard'' patterns in matrices of gene expression data, if they exist. In a cancer context, these checkerboards correspond to genes that are markedly up- or downregulated in patients with particular types of tumors. Our method, spectral biclustering, is based on the observation that checkerboard structures in matrices of expression data can be found in eigenvectors corresponding to characteristic expression patterns across genes or conditions. In addition, these eigenvectors can be readily identified by commonly used linear algebra approaches, in particular the singular value decomposition (SVD), coupled with closely integrated normalization steps. We present a number of variants of the approach, depending on whether the normalization over genes and conditions is done independently or in a coupled fashion. We then apply spectral biclustering to a selection of publicly available cancer expression data sets, and examine the degree to which the approach is able to identify checkerboard structures. Furthermore, we compare the performance of our biclustering methods against a number of reasonable benchmarks (e.g., direct application of SVD or normalized cuts to raw data).},
  langid = {english}
}

@article{sun2014BiforceLargescaleBicluster,
  title = {Bi-Force: {{Large-scale}} Bicluster Editing and Its Application to Gene Expression Data Biclustering},
  shorttitle = {Bi-{{Force}}},
  author = {Sun, Peng and Speicher, Nora K and R\"ottger, Richard and Guo, Jiong and Baumbach, Jan},
  date = {2014-05-01},
  journaltitle = {Nucleic Acids Research},
  shortjournal = {Nucleic Acids Res.},
  volume = {42},
  number = {9},
  pages = {e78-e78},
  issn = {0305-1048, 1362-4962},
  doi = {10.1093/nar/gku201},
  langid = {english}
}
@inproceedings{ding2006OrthogonalNonnegativeMatrix,
  title = {Orthogonal Nonnegative Matrix T-Factorizations for Clustering},
  booktitle = {Proceedings of the 12th {{ACM SIGKDD}} International Conference on {{Knowledge}} Discovery and Data Mining},
  author = {Ding, Chris and Li, Tao and Peng, Wei and Park, Haesun},
  date = {2006-08-20},
  series = {{{KDD}} '06},
  pages = {126--135},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/1150402.1150420},
  abstract = {Currently, most research on nonnegative matrix factorization (NMF)focus on 2-factor \$X=FG\^T\$ factorization. We provide a systematicanalysis of 3-factor \$X=FSG\^T\$ NMF. While it unconstrained 3-factor NMF is equivalent to it unconstrained 2-factor NMF, itconstrained 3-factor NMF brings new features to it constrained 2-factor NMF. We study the orthogonality constraint because it leadsto rigorous clustering interpretation. We provide new rules for updating \$F,S, G\$ and prove the convergenceof these algorithms. Experiments on 5 datasets and a real world casestudy are performed to show the capability of bi-orthogonal 3-factorNMF on simultaneously clustering rows and columns of the input datamatrix. We provide a new approach of evaluating the quality ofclustering on words using class aggregate distribution andmulti-peak distribution. We also provide an overview of various NMF extensions andexamine their relationships.目前，大多数关于非负矩阵分解（NMF）的研究都集中在2-factor \$X=FG\^T\$ factorization上。我们提供了 3 因子 \$X=FSG\^T\$ NMF 的系统分析。虽然无约束 3 因子 NMF 等同于无约束 2 因子 NMF，但有约束 3 因子 NMF 为其有约束 2 因子 NMF 带来了新特征。我们研究正交性约束，因为它会导致严格的聚类解释。我们提供了更新\$F、S、G\$的新规则，并证明了这些算法的收敛性。对 5 个数据集和真实世界的案例研究进行了实验，以显示双正交 3 因子 NMF 在同时聚类输入数据矩阵的行和列上的能力。我们提供了一种使用类聚合分布和多峰分布来评估词聚类质量的新方法。我们还提供了各种 NMF 扩展的概述并检查了它们的关系。},
  eventtitle = {{{ACM Knowledge Discovery}} and {{Data Mining}}},
  isbn = {978-1-59593-339-3},
  langid = {english}
}
@article{wang2019DualHypergraphRegularized,
  title = {Dual {{Hypergraph Regularized PCA}} for {{Biclustering}} of {{Tumor Gene Expression Data}}},
  author = {Wang, Xuesong and Liu, Jian and Cheng, Yuhu and Liu, Aiping and Chen, Enhong},
  date = {2019-12-01},
  journaltitle = {IEEE Transactions on Knowledge and Data Engineering},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  volume = {31},
  number = {12},
  pages = {2292--2303},
  issn = {1041-4347, 1558-2191, 2326-3865},
  doi = {10.1109/TKDE.2018.2874881},
  abstract = {Clustering is a powerful approach to analyze gene expression data which is crucial to the investigation of effective treatment of cancer. Many graph regularize-based clustering methods have been proposed and shown to be superior to the traditional clustering methods. However, they only focus on the inner structure in samples and fail to take the feature manifold into account. In gene expression data, it's practical to hypothesize that both the samples and the genes lie on nonlinear low dimensional manifolds, namely sample manifold and gene manifold, respectively. Therefore in this paper, incorporating the geometric structures in both samples and features, we propose a Dual Hypergraph Regularized PCA (DHPCA) method for biclustering of tumor data. First, for gene expression data, we construct two hypergraphs, i.e., sample hypergraph and gene hypergraph, to estimate the intrinsic geometric structures of samples and genes. Then, we introduce the hypergraph regularization on both gene side and sample side. Finally, our biclustering method is formulated as two hypergraph regularized PCA with closed-form solution. We experimentally validate our proposed DHPCA algorithm on real applications and the promising results indicate its potential in high dimension data analysis.},
  eventtitle = {{{IEEE Transactions}} on {{Knowledge}} and {{Data Engineering}}},
  langid = {english}
}
@article{junweihan2017BilateralKMeansAlgorithm,
  title = {Bilateral K-{{Means Algorithm}} for {{Fast Co-Clustering}}},
  author = {{Junwei Han} and {Kun Song} and {Feiping Nie} and {Xuelong Li}},
  date = {2017},
  abstract = {With the development of the information technology, the amount of data, e.g. text, image and video, has been increased rapidly. Efficiently clustering those large scale data sets is a challenge. To address this problem, this paper proposes a novel co-clustering method named bilateral k-means algorithm (BKM) for fast co-clustering. Different from traditional k-means algorithms, the proposed method has two indicator matrices P and Q and a diagonal matrix S to be solved, which represent the cluster memberships of samples and features, and the co-cluster centres, respectively. Therefore, it could implement different clustering tasks on the samples and features simultaneously. We also introduce an effective approach to solve the proposed method, which involves less multiplication. The computational complexity is analyzed. Extensive experiments on various types of data sets are conducted. Compared with the state-of-the-art clustering methods, the proposed BKM not only has faster computational speed, but also achieves promising clustering results.}
}
@article{chen2023ParallelNonNegativeMatrix,
  title = {Parallel Non-Negative Matrix Tri-Factorization for Text Data Co-Clustering},
  author = {Chen, Yufu and Lei, Zhiqi and Rao, Yanghui and Xie, Haoran and Wang, Fu Lee and Yin, Jian and Li, Qing},
  date = {2023-05},
  journaltitle = {IEEE Transactions on Knowledge and Data Engineering},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  volume = {35},
  number = {5},
  pages = {5132--5146},
  issn = {1558-2191},
  doi = {10.1109/TKDE.2022.3145489},
  abstract = {As a novel paradigm for data mining and dimensionality reduction, Non-negative Matrix Tri-Factorization (NMTF) has attracted much attention due to its notable performance and elegant mathematical derivation, and it has been applied to a plethora of real-world applications, such as text data co-clustering. However, the existing NMTF-based methods usually involve intensive matrix multiplications, which exhibits a major limitation of high computational complexity. With the explosion at both the size and the feature dimension of texts, there is a growing need to develop a parallel and scalable NMTF-based algorithm for text data co-clustering. To this end, we first show in this paper how to theoretically derive the original optimization problem of NMTF by introducing the Lagrangian multipliers. Then, we propose to solve the Lagrange dual objective function in parallel through an efficient distributed implementation. Extensive experiments on five benchmark corpora validate the effectiveness, efficiency, and scalability of our distributed parallel update algorithm for an NMTF-based text data co-clustering method.},
  eventtitle = {{{IEEE Transactions}} on {{Knowledge}} and {{Data Engineering}}}
}
@article{yan2017CoclusteringMultidimensionalBig,
  title = {Coclustering of {{Multidimensional Big Data}}: {{A Useful Tool}} for {{Genomic}}, {{Financial}}, and {{Other Data Analysis}}},
  author = {Yan, Hong},
  date = {2017-04},
  journaltitle = {IEEE Systems, Man, and Cybernetics Magazine},
  shortjournal = {IEEE Syst. Man Cybern. Mag.},
  volume = {3},
  number = {2},
  pages = {23--30},
  publisher = {{Institute of Electrical and Electronics Engineers (IEEE)}},
  issn = {2333-942X, 2380-1298},
  doi = {10.1109/msmc.2017.2664218},
  abstract = {The analysis of a multidimensional data array is necessary in many applications. Although a data set can be very large, it is possible that meaningful and coherent patterns embedded in the data array are much smaller in size. For example, in genomic data, we may want to find a subset of genes that coexpress under a subset of conditions. In this article, I will explain coclustering algorithms for solving the coherent pattern-detection problem. In these methods, a coherent pattern corresponds to a low-rank matrix or tensor and can be represented as an intersection of hyperplanes in a high-dimensional space. We can then extract coherent patterns from the large data array by detecting hyperplanes. Examples will be provided to demonstrate the effectiveness of the coclustering algorithms for solving unsupervised pattern classification problems.},
  langid = {english}
}
@article{chi2020ProvableConvexCoclustering,
  title = {Provable {{Convex Co-Clustering}} of {{Tensors}}},
  author = {Chi, Eric C and Gaines, Brian R and Sun, Will Wei and Zhou, Hua and Yang, Jian},
  date = {2020},
  journaltitle = {The Journal of Machine Learning Research},
  shortjournal = {J. Mach. Learn. Res.},
  volume = {21},
  number = {1},
  pages = {8792--8849},
  publisher = JMLRORG,
  abstract = {Cluster analysis is a fundamental tool for pattern discovery of complex heterogeneous data. Prevalent clustering methods mainly focus on vector or matrix-variate data and are not applicable to general-order tensors, which arise frequently in modern scientific and business applications. Moreover, there is a gap between statistical guarantees and computational efficiency for existing tensor clustering solutions due to the nature of their non-convex formulations. In this work, we bridge this gap by developing a provable convex formulation of tensor co-clustering. Our convex co-clustering (CoCo) estimator enjoys stability guarantees and its computational and storage costs are polynomial in the size of the data. We further establish a non-asymptotic error bound for the CoCo estimator, which reveals a surprising ``blessing of dimensionality'' phenomenon that does not exist in vector or matrix-variate cluster analysis. Our theoretical findings are supported by extensive simulated studies. Finally, we apply the CoCo estimator to the cluster analysis of advertisement click tensor data from a major online company. Our clustering results provide meaningful business insights to improve advertising effectiveness.},
  langid = {english}
}
@inproceedings{dhillon2003InformationtheoreticCoclustering,
  title = {Information-Theoretic Co-Clustering},
  booktitle = {Proceedings of the Ninth {{ACM SIGKDD}} International Conference on {{Knowledge}} Discovery and Data Mining  - {{KDD}} '03},
  author = {Dhillon, Inderjit S. and Mallela, Subramanyam and Modha, Dharmendra S.},
  date = {2003-08-24},
  series = {{{KDD}} '03},
  pages = {89--98},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/956750.956764},
  abstract = {Two-dimensional contingency or co-occurrence tables arise frequently in important applications such as text, web-log and market-basket data analysis. A basic problem in contingency table analysis is co-clustering: simultaneous clustering of the rows and columns. A novel theoretical formulation views the contingency table as an empirical joint probability distribution of two discrete random variables and poses the co-clustering problem as an optimization problem in information theory---the optimal co-clustering maximizes the mutual information between the clustered random variables subject to constraints on the number of row and column clusters. We present an innovative co-clustering algorithm that monotonically increases the preserved mutual information by intertwining both the row and column clusterings at all stages. Using the practical example of simultaneous word-document clustering, we demonstrate that our algorithm works well in practice, especially in the presence of sparsity and high-dimensionality.},
  eventtitle = {{{ACM Knowledge Discovery}} and {{Data Mining}}},
  isbn = {978-1-58113-737-8},
  langid = {english}
}
