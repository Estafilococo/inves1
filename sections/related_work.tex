%%%
% File: /latex/big-cocluster-paper/sections/related_work.tex
% Created Date: Thursday, July 11th 2024
% Author: Zihan
% -----
% Last Modified: Sunday, 14th July 2024 9:43:56 pm
% Modified By: the developer formerly known as Zihan at <wzh4464@gmail.com>
% -----
% HISTORY:
% Date      		By   	Comments
% ----------		------	---------------------------------------------------------
%%%

\section{Related work}
\label{sec:related_work}
\subsection{Co-clustering Methods}
Co-clustering methods, broadly categorized into graph-based and matrix factorization-based approaches, have limitations in handling large datasets. Graph-based methods like Flexible Bipartite Graph Co-clustering (FBGPC) \cite{chen2023FastFlexibleBipartite} directly apply flexible bipartite graph models. Matrix factorization-based methods, such as Non-negative Matrix Tri-Factorization (NMTF) \cite{long2005CoclusteringBlockValue}, decompose data to cluster samples and features separately. Deep Co-Clustering (DeepCC) \cite{dongkuanxu2019DeepCoClustering}, which integrates deep autoencoders with Gaussian Mixture Models, also faces efficiency challenges with diverse data types and large datasets.

\subsection{Parallelizing Co-clustering}
Parallel methods are crucial for big data processing. The CoClusterD framework \cite{cheng2015CoClusterDDistributedFramework} uses Alternating Minimization Co-clustering (AMCC) in a distributed environment but struggles with guaranteed convergence. Chen \textit{et al.} \cite{chen2023ParallelNonNegativeMatrix} introduced a parallel non-negative matrix tri-factorization method to accelerate computations but still faces difficulties with very large datasets.

Our method addresses these challenges with a divide-and-conquer strategy, partitioning large matrices into smaller submatrices for parallel co-clustering, and then hierarchically merging the results. This approach significantly enhances scalability and efficiency, providing a robust solution for high-dimensional big data.
