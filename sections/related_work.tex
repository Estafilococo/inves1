% sectionis/related_work.tex

\section{Related work}
\label{sec:related_work}
\subsection{Co-clustering Methods}
Co-clustering methods employing Singular Value Decomposition (SVD) can be broadly categorized into graph-based and matrix factorization-based approaches
\cite{dhillon2001CoclusteringDocumentsWords}. A prominent example of graph-based co-clustering is the Flexible Bipartite Graph Co-clustering (FBGPC) \cite{chen2023FastFlexibleBipartitea}, which directly applies a flexible bipartite graph model to the original data. In contrast, Non-negative Matrix Tri-Factorization (NMTF) represents a leading matrix factorization-based method that decomposes data into multiple matrices to independently cluster samples and features, subsequently discovering the relationships between them \cite{long2005CoclusteringBlockValue}. Our method is orthogonal to NMTF, allowing for potential integration to enhance co-clustering efficiency.

Another innovative method, Deep Co-Clustering (DeepCC), integrates deep autoencoders with Gaussian Mixture Models to improve data clustering \cite{dongkuanxu2019DeepCoClustering}. Despite its advancements, DeepCC struggles with computational efficiency, particularly with diverse data types and iterative processes dependent on data sparsity.

\subsection{Parallelizing Co-clustering}

Parallel co-clustering methods have emerged as a vital solution to the challenges of processing big data. The CoClusterD framework by Cheng \textit{et al.} \cite{cheng2015CoClusterDDistributedFramework} utilizes an Alternating Minimization Co-clustering (AMCC) algorithm with sequential updates in a distributed environment. However, this method faces challenges with guaranteed convergence, leading to potential inefficiencies.

While matrix factorization techniques have shown promise for co-clustering large datasets, scaling to massive high-dimensional data remains an open challenge. Chen \textit{et al.}\cite{chen2023ParallelNonNegativeMatrix} proposed a parallel non-negative matrix tri-factorization method that distributes computation across multiple nodes to accelerate factorizations. However, even these advanced methods encounter difficulties with extremely large datasets.

Our proposed method adopts a divide-and-conquer strategy, partitioning the input matrix into smaller submatrices, which are then co-clustered in parallel. This technique reduces the complexity imposed by high dimensionality and combines the results to form the final co-clusters. This novel approach addresses the computational challenges and introduces a scalable solution for big data.